-------------------------Setting up project structure---------------------------

1. Create repo, clone it in local
2. Create a virtual environment named 'atlas' - conda create -n atlas python=3.10
3. Activate the virtual environment - conda activate atlas
4. pip install cookiecutter
5. cookiecutter -c v1 https://github.com/drivendata/cookiecutter-data-science
6. Rename src.models -> src.model
   copy the provided requirements.txt file and do "pip install -r requirements.txt"
7. git add - commit - push

-------------------------Setup MLFlow on Dagshub---------------------------
8. Go to: https://dagshub.com/dashboard
9. Create > New Repo > Connect a repo > (Github) Connect > Select your repo > Connect
10. Copy experiment tracking url and code snippet. (Also try: Go To MLFlow UI)
    https://dagshub.com/rnjt80/credit_card_fraud_detection.mlflow

    dagshub.init(repo_owner='rnjt80', repo_name='credit_card_fraud_detection', mlflow=True)

11. pip install dagshub & mlflow

12. Run the exp notebooks
13. git add - commit - push

14. dvc init
15. create a local folder as "local_s3" (temporary work)
16. on terminal - "dvc remote add -d mylocal local_s3"

17. Add code to below files/folders inside src dir:
    - logger
    - data_ingestion.py
    - data_preprocessing.py
    - feature_engineering.py
    - model_building.py
    - model_evaluation.py
    - register_model.py
18. add file - dvc.yaml
19. add file - params.yaml
20. DVC pipeline is ready to run - dvc repro
21. Once do - dvc status
22. git add - commit - push

23. Need to add S3 as remote storage - Create IAM User(keep cred) and S3 bucket
24. pip install - dvc[s3] & awscli
25. Checking/deleting dvc remote (optional) - [dvc remote list & dvc remote remove <name>] 
26. Set aws cred - aws configure
27. Add s3 as dvc remote storage - dvc remote add -d myremote s3://learnyard-proj1-bucket

28. Create new dir - flask_app | Inside that, add rest of the files and dir
29. pip install flask and run the app (dvc push - to push data to S3)

30. pip freeze > requirements.txt
31. Add .github/workflows/ci.yaml file

31.2. Create key token on Dagshub for auth: Go to dagshub repo > Your settings > Tokens > Generate new token
   
    >> Add this auth token to github secret&var and update on ci file

31.3. Add dir "tests"&"scripts" and files within. This will contain our test related scripts for CI.

>>>>> Moving to Docker <<<<<
32. pip install pipreqs
33. cd flask_app & do "pipreqs . --force"
34. Add dockerfile and start docker-desktop in background
35. go to root dir and: "docker build -t creditcard_fraud:latest ."
36. Try running the image: "docker run -p 8888:5000 creditcard_fraud:latest"
    - This run will give 'OSError: capstone_test environment variable is not set'...obviously
    - alternate: docker run -p 8888:5000 -e dagshub_token=f10c66bf37ca853638d7596697e1292a1c51f217 creditcard_fraud:latest
    and check if the app is running on port 8888

37. Create secrets in k8s for dagshub token and dockerhub creds
    - kubectl create secret generic dagshubtoken --from-literal=dagshub_token=e915ac7b7XXXXXXXca4f93f462f33be -n creditcard-fraud
    - ubectl create secret docker-registry dockerhub-creds --docker-server='https://hub.docker.com/' --docker-username='rnjt80' --docker-password='dckr_pat_8iiRM' -n creditcard-fraud

38. Create k8s folder and Add deployment.yaml, service.yaml and ingress.yaml file.

39. Install ArgoCD using the official manifests:
    >> kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml
    >> Expose the ArgoCD server (for local dev) - By default, ArgoCD server is ClusterIP (internal only), so letâ€™s patch it to 
    NodePort (so you can access it via your browser): kubectl patch svc argocd-server -n argocd -p '{\"spec\": {\"type\": \"NodePort\"}}'

39. In Argocd create a application with the github repo and path k8s.
40. click on SYNC button apply your Kubernetes manifests. This will deploy your app to Kubernetes cluster.
41. Now add steps to cicd github action workflow file to change the image name in deployment file as soon as the new image is created by CICD jobs
42. Do git commit and push 
